{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R8_External_Lab_Ques_CIFAR10_Transfer_Learning_TFIDF_Text_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGIsF1ADyJ58",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning CIFAR10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-n6tVFayGBe",
        "colab_type": "text"
      },
      "source": [
        "* Train a simple convnet on the CIFAR dataset the first 5 output classes [0..4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the last 5 ouput classes [5..9].\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq8ejXHJyGYq",
        "colab_type": "text"
      },
      "source": [
        "### 1. Import CIFAR10 data and create 2 datasets with one dataset having classes from 0 to 4 and other having classes from 5 to 9 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWYbxnBayFUP",
        "colab_type": "code",
        "outputId": "bf6d4718-ad46-4981-ca2d-b153897943bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import os\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, Conv2D, Flatten, Dense, Dropout, Reshape, MaxPool2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GG3Hb5fTUdv",
        "colab_type": "code",
        "outputId": "fffc6dc7-9b45-4417-be4d-0d04ef0e79a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(trainX, trainY), (testX, testY) = cifar10.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXCTzSH9TUWG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting data set into 2 categories one with 0-4 labels & other with 5-9 labels.\n",
        "\n",
        "x_train_zero_four = []\n",
        "y_train_zero_four = []\n",
        "x_train_five_nine = []\n",
        "y_train_five_nine = []\n",
        "\n",
        "x_test_zero_four = []\n",
        "y_test_zero_four = []\n",
        "x_test_five_nine = []\n",
        "y_test_five_nine = []\n",
        "\n",
        "for idx,x in enumerate(trainY):\n",
        "    if (x>4):\n",
        "        x_train_five_nine.append(trainX[idx])\n",
        "        y_train_five_nine.append(trainY[idx])\n",
        "    else:\n",
        "        x_train_zero_four.append(trainX[idx])\n",
        "        y_train_zero_four.append(trainY[idx])\n",
        "\n",
        "        \n",
        "for idx,y in enumerate(testY):\n",
        "    if (y>4):\n",
        "        x_test_five_nine.append(testX[idx])\n",
        "        y_test_five_nine.append(testY[idx])\n",
        "    else:\n",
        "        x_test_zero_four.append(testX[idx])\n",
        "        y_test_zero_four.append(testY[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtCKmQh4yXhT",
        "colab_type": "text"
      },
      "source": [
        "### 2. Use One-hot encoding to divide y_train and y_test into required no of output classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udlVnBiKg7od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_zero_four = to_categorical(y_train_zero_four, num_classes=5)\n",
        "y_test_zero_four = to_categorical(y_test_zero_four, num_classes=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uN5O2kJ3yYa6",
        "colab_type": "code",
        "outputId": "0e8bb874-716a-4da6-ab30-db024cccf34d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train_zero_four[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MCAy9s4G_Cg",
        "colab_type": "code",
        "outputId": "4a1e59f7-9da6-45b0-b256-f7ac3956c83d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# printing shape of each data set post splitting\n",
        "\n",
        "x_train_zero_four = np.asarray(x_train_zero_four,dtype='float')\n",
        "y_train_zero_four = np.asarray(y_train_zero_four,dtype='float')\n",
        "x_train_five_nine = np.asarray(x_train_five_nine,dtype='float')\n",
        "y_train_five_nine = np.asarray(y_train_five_nine,dtype='float')\n",
        "x_test_zero_four = np.asarray(x_test_zero_four,dtype='float')\n",
        "y_test_zero_four = np.asarray(y_test_zero_four,dtype='float')\n",
        "x_test_five_nine = np.asarray(x_test_five_nine,dtype='float')\n",
        "y_test_five_nine = np.asarray(y_test_five_nine,dtype='float')\n",
        "print(x_train_zero_four.shape)\n",
        "print(y_train_zero_four.shape)\n",
        "print(x_train_five_nine.shape)\n",
        "print(y_train_five_nine.shape)\n",
        "print(x_test_zero_four.shape)\n",
        "print(y_test_zero_four.shape)\n",
        "print(x_test_five_nine.shape)\n",
        "print(y_test_five_nine.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 32, 32, 3)\n",
            "(25000, 5)\n",
            "(25000, 32, 32, 3)\n",
            "(25000, 1)\n",
            "(5000, 32, 32, 3)\n",
            "(5000, 5)\n",
            "(5000, 32, 32, 3)\n",
            "(5000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE44hph9HOtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshaping data\n",
        "\n",
        "x_train_zero_four = x_train_zero_four.reshape(x_train_zero_four.shape[0], 32, 32, 3).astype('float32')\n",
        "x_test_zero_four = x_test_zero_four.reshape(x_test_zero_four.shape[0], 32, 32, 3).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hczy-CAxHSys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalise data\n",
        "\n",
        "x_train_zero_four /= 255\n",
        "x_test_zero_four /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S21aUJ-mHSLf",
        "colab_type": "code",
        "outputId": "af10eaf2-c26b-430b-d661-86cd8182ec58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(x_train_zero_four.shape)\n",
        "print(y_test_zero_four.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 32, 32, 3)\n",
            "(5000, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuOiKWfeybAl",
        "colab_type": "text"
      },
      "source": [
        "### 3. Build a sequential neural network model which can classify the classes 0 to 4 of CIFAR10 dataset with at least 80% accuracy on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3_lXAei_d60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clear out tensorflow memory\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HzxNbiiyoBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_CNN_model():\n",
        "    #Initialize Sequential model\n",
        "    model = Sequential()\n",
        "\n",
        "    #normalize data\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    #Add first convolutional layer\n",
        "    model.add(Conv2D(32, #Number of filters \n",
        "                                    kernel_size=(3,3), #Size of the filter\n",
        "                                    activation='relu'))\n",
        "\n",
        "    #Add second convolutional layer\n",
        "    model.add(Conv2D(32, #Number of filters \n",
        "                                    kernel_size=(3,3), #Size of the filter\n",
        "                                    activation='relu'))\n",
        "\n",
        "    #Add MaxPooling layer\n",
        "    model.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    #Flatten the output\n",
        "    model.add(Flatten())\n",
        "\n",
        "    #Dense layer\n",
        "    model.add(Dense(200, activation='relu'))\n",
        "\n",
        "    #Add another dropout layer\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    #Dense layer\n",
        "    model.add(Dense(100, activation='relu'))\n",
        "\n",
        "    #Add another dropout layer\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    #Output layer\n",
        "    model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZspn3S88zhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = create_CNN_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roqMENnX_-bT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Saving the best model using model checkpoint callback\n",
        "model_checkpoint = ModelCheckpoint('flowertransfer_learning_ext_cnn.h5', \n",
        "                                    save_best_only=True, \n",
        "                                    monitor='val_acc', \n",
        "                                    mode='max', \n",
        "                                    verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tIuBCNP8zUQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lwznm7tZe8T",
        "colab_type": "code",
        "outputId": "f66d4b5a-9e91-4bbb-a1ae-423448756c84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "model.fit(x_train_zero_four, y_train_zero_four, batch_size=32, epochs=30, validation_split=0.2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "20000/20000 [==============================] - 11s 528us/sample - loss: 1.0285 - accuracy: 0.5849 - val_loss: 0.8148 - val_accuracy: 0.6782\n",
            "Epoch 2/30\n",
            "20000/20000 [==============================] - 3s 149us/sample - loss: 0.7630 - accuracy: 0.7088 - val_loss: 0.7167 - val_accuracy: 0.7248\n",
            "Epoch 3/30\n",
            "20000/20000 [==============================] - 3s 153us/sample - loss: 0.6031 - accuracy: 0.7711 - val_loss: 0.6742 - val_accuracy: 0.7506\n",
            "Epoch 4/30\n",
            "20000/20000 [==============================] - 3s 143us/sample - loss: 0.4895 - accuracy: 0.8188 - val_loss: 0.6497 - val_accuracy: 0.7642\n",
            "Epoch 5/30\n",
            "20000/20000 [==============================] - 3s 146us/sample - loss: 0.3684 - accuracy: 0.8658 - val_loss: 0.7236 - val_accuracy: 0.7592\n",
            "Epoch 6/30\n",
            "20000/20000 [==============================] - 3s 145us/sample - loss: 0.2963 - accuracy: 0.8906 - val_loss: 0.7351 - val_accuracy: 0.7678\n",
            "Epoch 7/30\n",
            "20000/20000 [==============================] - 3s 145us/sample - loss: 0.2360 - accuracy: 0.9174 - val_loss: 0.7916 - val_accuracy: 0.7596\n",
            "Epoch 8/30\n",
            "20000/20000 [==============================] - 3s 147us/sample - loss: 0.1903 - accuracy: 0.9317 - val_loss: 0.8422 - val_accuracy: 0.7660\n",
            "Epoch 9/30\n",
            "20000/20000 [==============================] - 3s 145us/sample - loss: 0.1660 - accuracy: 0.9427 - val_loss: 0.9523 - val_accuracy: 0.7584\n",
            "Epoch 10/30\n",
            "20000/20000 [==============================] - 3s 144us/sample - loss: 0.1409 - accuracy: 0.9505 - val_loss: 0.9265 - val_accuracy: 0.7668\n",
            "Epoch 11/30\n",
            "20000/20000 [==============================] - 3s 147us/sample - loss: 0.1139 - accuracy: 0.9602 - val_loss: 1.0200 - val_accuracy: 0.7722\n",
            "Epoch 12/30\n",
            "20000/20000 [==============================] - 3s 148us/sample - loss: 0.1086 - accuracy: 0.9635 - val_loss: 1.1473 - val_accuracy: 0.7650\n",
            "Epoch 13/30\n",
            "20000/20000 [==============================] - 3s 144us/sample - loss: 0.1046 - accuracy: 0.9650 - val_loss: 1.0830 - val_accuracy: 0.7588\n",
            "Epoch 14/30\n",
            "20000/20000 [==============================] - 3s 143us/sample - loss: 0.0970 - accuracy: 0.9660 - val_loss: 1.1859 - val_accuracy: 0.7564\n",
            "Epoch 15/30\n",
            "20000/20000 [==============================] - 3s 142us/sample - loss: 0.0930 - accuracy: 0.9684 - val_loss: 1.1226 - val_accuracy: 0.7692\n",
            "Epoch 16/30\n",
            "20000/20000 [==============================] - 3s 148us/sample - loss: 0.0856 - accuracy: 0.9714 - val_loss: 1.1128 - val_accuracy: 0.7654\n",
            "Epoch 17/30\n",
            "20000/20000 [==============================] - 3s 151us/sample - loss: 0.0839 - accuracy: 0.9722 - val_loss: 1.2326 - val_accuracy: 0.7632\n",
            "Epoch 18/30\n",
            "20000/20000 [==============================] - 3s 149us/sample - loss: 0.0769 - accuracy: 0.9746 - val_loss: 1.2104 - val_accuracy: 0.7576\n",
            "Epoch 19/30\n",
            "20000/20000 [==============================] - 3s 152us/sample - loss: 0.0745 - accuracy: 0.9761 - val_loss: 1.2104 - val_accuracy: 0.7706\n",
            "Epoch 20/30\n",
            "20000/20000 [==============================] - 3s 146us/sample - loss: 0.0677 - accuracy: 0.9769 - val_loss: 1.2995 - val_accuracy: 0.7538\n",
            "Epoch 21/30\n",
            "20000/20000 [==============================] - 3s 144us/sample - loss: 0.0730 - accuracy: 0.9765 - val_loss: 1.1457 - val_accuracy: 0.7674\n",
            "Epoch 22/30\n",
            "20000/20000 [==============================] - 3s 146us/sample - loss: 0.0701 - accuracy: 0.9755 - val_loss: 1.2169 - val_accuracy: 0.7686\n",
            "Epoch 23/30\n",
            "20000/20000 [==============================] - 3s 146us/sample - loss: 0.0571 - accuracy: 0.9813 - val_loss: 1.3241 - val_accuracy: 0.7612\n",
            "Epoch 24/30\n",
            "20000/20000 [==============================] - 3s 150us/sample - loss: 0.0607 - accuracy: 0.9797 - val_loss: 1.4005 - val_accuracy: 0.7622\n",
            "Epoch 25/30\n",
            "20000/20000 [==============================] - 3s 150us/sample - loss: 0.0603 - accuracy: 0.9808 - val_loss: 1.2415 - val_accuracy: 0.7642\n",
            "Epoch 26/30\n",
            "20000/20000 [==============================] - 3s 151us/sample - loss: 0.0627 - accuracy: 0.9790 - val_loss: 1.2968 - val_accuracy: 0.7576\n",
            "Epoch 27/30\n",
            "20000/20000 [==============================] - 3s 144us/sample - loss: 0.0581 - accuracy: 0.9812 - val_loss: 1.3152 - val_accuracy: 0.7706\n",
            "Epoch 28/30\n",
            "20000/20000 [==============================] - 3s 143us/sample - loss: 0.0591 - accuracy: 0.9808 - val_loss: 1.2251 - val_accuracy: 0.7702\n",
            "Epoch 29/30\n",
            "20000/20000 [==============================] - 3s 148us/sample - loss: 0.0539 - accuracy: 0.9833 - val_loss: 1.2617 - val_accuracy: 0.7694\n",
            "Epoch 30/30\n",
            "20000/20000 [==============================] - 3s 151us/sample - loss: 0.0430 - accuracy: 0.9869 - val_loss: 1.3566 - val_accuracy: 0.7642\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f593ee1a080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woTfNst_ynRG",
        "colab_type": "text"
      },
      "source": [
        "### 4. In the model which was built above (for classification of classes 0-4 in CIFAR10), make only the dense layers to be trainable and conv layers to be non-trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_VCDB3Byb1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Freezing layers in the model which don't have 'dense' in their name\n",
        "for layer in model.layers:\n",
        "  if('dense' not in layer.name): #prefix detection to freeze layers which does not have dense\n",
        "    #Freezing a layer\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-uUPqWpyeyX",
        "colab_type": "text"
      },
      "source": [
        "### 5. Utilize the the model trained on CIFAR 10 (classes 0 to 4) to classify the classes 5 to 9 of CIFAR 10  (Use Transfer Learning) <br>\n",
        "Achieve an accuracy of more than 85% on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YTaN_u9cIWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reshape\n",
        "x_train_five_nine = x_train_five_nine.reshape(x_train_five_nine.shape[0], 32, 32, 3).astype('float32')\n",
        "x_test_five_nine = x_test_five_nine.reshape(x_test_five_nine.shape[0], 32, 32, 3).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szHjJgDvyfCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_five_nine /= 255\n",
        "x_test_five_nine /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnbn4MJJcLYH",
        "colab_type": "code",
        "outputId": "a37902ba-7e3d-4280-a400-c43ce1115e89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# encoding the labels for 5-9 of cifar 10 data set\n",
        "y_train_five_nine = y_train_five_nine -5\n",
        "y_test_five_nine = y_test_five_nine - 5\n",
        "\n",
        "print(y_test_five_nine[0])\n",
        "\n",
        "y_train_five_nine = to_categorical(y_train_five_nine, 5)\n",
        "y_test_five_nine = to_categorical(y_test_five_nine, 5)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcx41mjScLTv",
        "colab_type": "code",
        "outputId": "617b7b32-965a-4f01-badf-f74d8cc106d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "#Transfer learning . Fit the model built on 0-4 data onto data 5-9\n",
        "model.fit(x_train_five_nine, y_train_five_nine, batch_size=32, epochs=20,validation_split=0.2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/20\n",
            "20000/20000 [==============================] - 3s 168us/sample - loss: 1.0245 - accuracy: 0.6309 - val_loss: 0.5913 - val_accuracy: 0.7842\n",
            "Epoch 2/20\n",
            "20000/20000 [==============================] - 3s 148us/sample - loss: 0.5381 - accuracy: 0.8045 - val_loss: 0.4826 - val_accuracy: 0.8300\n",
            "Epoch 3/20\n",
            "20000/20000 [==============================] - 3s 148us/sample - loss: 0.4091 - accuracy: 0.8544 - val_loss: 0.4833 - val_accuracy: 0.8222\n",
            "Epoch 4/20\n",
            "20000/20000 [==============================] - 3s 142us/sample - loss: 0.3207 - accuracy: 0.8870 - val_loss: 0.5507 - val_accuracy: 0.8256\n",
            "Epoch 5/20\n",
            "20000/20000 [==============================] - 3s 140us/sample - loss: 0.2587 - accuracy: 0.9084 - val_loss: 0.4972 - val_accuracy: 0.8410\n",
            "Epoch 6/20\n",
            "20000/20000 [==============================] - 3s 142us/sample - loss: 0.2017 - accuracy: 0.9270 - val_loss: 0.5366 - val_accuracy: 0.8394\n",
            "Epoch 7/20\n",
            "20000/20000 [==============================] - 3s 147us/sample - loss: 0.1744 - accuracy: 0.9381 - val_loss: 0.5745 - val_accuracy: 0.8420\n",
            "Epoch 8/20\n",
            "20000/20000 [==============================] - 3s 146us/sample - loss: 0.1483 - accuracy: 0.9499 - val_loss: 0.5938 - val_accuracy: 0.8432\n",
            "Epoch 9/20\n",
            "20000/20000 [==============================] - 3s 153us/sample - loss: 0.1310 - accuracy: 0.9545 - val_loss: 0.6305 - val_accuracy: 0.8466\n",
            "Epoch 10/20\n",
            "20000/20000 [==============================] - 3s 147us/sample - loss: 0.1135 - accuracy: 0.9617 - val_loss: 0.6658 - val_accuracy: 0.8352\n",
            "Epoch 11/20\n",
            "20000/20000 [==============================] - 3s 146us/sample - loss: 0.1072 - accuracy: 0.9645 - val_loss: 0.6349 - val_accuracy: 0.8436\n",
            "Epoch 12/20\n",
            "20000/20000 [==============================] - 3s 147us/sample - loss: 0.0945 - accuracy: 0.9685 - val_loss: 0.6718 - val_accuracy: 0.8336\n",
            "Epoch 13/20\n",
            "20000/20000 [==============================] - 3s 147us/sample - loss: 0.0873 - accuracy: 0.9702 - val_loss: 0.7370 - val_accuracy: 0.8330\n",
            "Epoch 14/20\n",
            "20000/20000 [==============================] - 3s 153us/sample - loss: 0.0858 - accuracy: 0.9714 - val_loss: 0.7224 - val_accuracy: 0.8390\n",
            "Epoch 15/20\n",
            "20000/20000 [==============================] - 3s 145us/sample - loss: 0.0822 - accuracy: 0.9735 - val_loss: 0.7553 - val_accuracy: 0.8350\n",
            "Epoch 16/20\n",
            "20000/20000 [==============================] - 3s 147us/sample - loss: 0.0772 - accuracy: 0.9741 - val_loss: 0.8082 - val_accuracy: 0.8316\n",
            "Epoch 17/20\n",
            "20000/20000 [==============================] - 3s 143us/sample - loss: 0.0740 - accuracy: 0.9762 - val_loss: 0.7188 - val_accuracy: 0.8490\n",
            "Epoch 18/20\n",
            "20000/20000 [==============================] - 3s 143us/sample - loss: 0.0688 - accuracy: 0.9775 - val_loss: 0.7096 - val_accuracy: 0.8478\n",
            "Epoch 19/20\n",
            "20000/20000 [==============================] - 3s 145us/sample - loss: 0.0676 - accuracy: 0.9783 - val_loss: 0.7392 - val_accuracy: 0.8380\n",
            "Epoch 20/20\n",
            "20000/20000 [==============================] - 3s 153us/sample - loss: 0.0617 - accuracy: 0.9802 - val_loss: 0.7988 - val_accuracy: 0.8432\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f593ec14048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zDuRecXzEtr",
        "colab_type": "text"
      },
      "source": [
        "# Text classification using TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMPlEJhHzb6P",
        "colab_type": "text"
      },
      "source": [
        "### 6. Load the dataset from sklearn.datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe-B59u3zHNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRrMemVQzbHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "categories = ['alt.atheism', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sZX0UbJzmg5",
        "colab_type": "text"
      },
      "source": [
        "### 7. Training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CITr_5aXziJ2",
        "colab_type": "code",
        "outputId": "ae8808ee-4172-46fe-8ba6-f47820f52499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcESc5QXzr6p",
        "colab_type": "text"
      },
      "source": [
        "### 8. Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysInblUMzpvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DriL2yZ50DQq",
        "colab_type": "text"
      },
      "source": [
        "###  a.  You can access the values for the target variable using .target attribute \n",
        "###  b. You can access the name of the class in the target variable with .target_names\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlUuai99z1hX",
        "colab_type": "code",
        "outputId": "cf6a39cd-b31d-4473-fb01-94674966a2f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "twenty_train.target"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, ..., 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEKzaDfSz5E-",
        "colab_type": "code",
        "outputId": "83b74017-c244-4374-89cd-4dc02a12404f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "twenty_train.target_names"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clBMKHzC0_N1",
        "colab_type": "code",
        "outputId": "b1607fe0-181f-4493-cf23-42db02f31e1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "twenty_train.data[0:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert tif/img/tga files into LaserJet III format.  We would also like to\\ndo the same, converting to HPGL (HP plotter) files.\\n\\nPlease email any response.\\n\\nIs this the correct group?\\n\\nThanks in advance.  Michael.\\n-- \\nMichael Collier (Programmer)                 The Computer Unit,\\nEmail: M.P.Collier@uk.ac.city                The City University,\\nTel: 071 477-8000 x3769                      London,\\nFax: 071 477-8565                            EC1V 0HB.\\n',\n",
              " \"From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\nSubject: help: Splitting a trimming region along a mesh \\nOrganization: University Of Kentucky, Dept. of Math Sciences\\nLines: 28\\n\\n\\n\\n\\tHi,\\n\\n\\tI have a problem, I hope some of the 'gurus' can help me solve.\\n\\n\\tBackground of the problem:\\n\\tI have a rectangular mesh in the uv domain, i.e  the mesh is a \\n\\tmapping of a 3d Bezier patch into 2d. The area in this domain\\n\\twhich is inside a trimming loop had to be rendered. The trimming\\n\\tloop is a set of 2d Bezier curve segments.\\n\\tFor the sake of notation: the mesh is made up of cells.\\n\\n\\tMy problem is this :\\n\\tThe trimming area has to be split up into individual smaller\\n\\tcells bounded by the trimming curve segments. If a cell\\n\\tis wholly inside the area...then it is output as a whole ,\\n\\telse it is trivially rejected. \\n\\n\\tDoes any body know how thiss can be done, or is there any algo. \\n\\tsomewhere for doing this.\\n\\n\\tAny help would be appreciated.\\n\\n\\tThanks, \\n\\tAni.\\n-- \\nTo get irritated is human, to stay cool, divine.\\n\",\n",
              " \"From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSubject: Re: harrassed at work, could use some prayers\\nOrganization: =CSE Dept., U.C. San Diego\\nLines: 63\\n\\n(Well, I'll email also, but this may apply to other people, so\\nI'll post also.)\\n\\n>I've been working at this company for eight years in various\\n>engineering jobs.  I'm female.  Yesterday I counted and realized that\\n>on seven different occasions I've been sexually harrassed at this\\n>company.\\n\\n>I dreaded coming back to work today.  What if my boss comes in to ask\\n>me some kind of question...\\n\\nYour boss should be the person bring these problems to.  If he/she\\ndoes not seem to take any action, keep going up higher and higher.\\nSexual harrassment does not need to be tolerated, and it can be an\\nenormous emotional support to discuss this with someone and know that\\nthey are trying to do something about it.  If you feel you can not\\ndiscuss this with your boss, perhaps your company has a personnel\\ndepartment that can work for you while preserving your privacy.  Most\\ncompanies will want to deal with this problem because constant anxiety\\ndoes seriously affect how effectively employees do their jobs.\\n\\nIt is unclear from your letter if you have done this or not.  It is\\nnot inconceivable that management remains ignorant of employee\\nproblems/strife even after eight years (it's a miracle if they do\\nnotice).  Perhaps your manager did not bring to the attention of\\nhigher ups?  If the company indeed does seem to want to ignore the\\nentire problem, there may be a state agency willing to fight with\\nyou.  (check with a lawyer, a women's resource center, etc to find out)\\n\\nYou may also want to discuss this with your paster, priest, husband,\\netc.  That is, someone you know will not be judgemental and that is\\nsupportive, comforting, etc.  This will bring a lot of healing.\\n\\n>So I returned at 11:25, only to find that ever single\\n>person had already left for lunch.  They left at 11:15 or so.  No one\\n>could be bothered to call me at the other building, even though my\\n>number was posted.\\n\\nThis happens to a lot of people.  Honest.  I believe it may seem\\nto be due to gross insensitivity because of the feelings you are\\ngoing through.  People in offices tend to be more insensitive while\\nworking than they normally are (maybe it's the hustle or stress or...)\\nI've had this happen to me a lot, often because they didn't realize\\nmy car was broken, etc.  Then they will come back and wonder why I\\ndidn't want to go (this would tend to make me stop being angry at\\nbeing ignored and make me laugh).  Once, we went off without our\\nboss, who was paying for the lunch :-)\\n\\n>For this\\n>reason I hope good Mr. Moderator allows me this latest indulgence.\\n\\nWell, if you can't turn to the computer for support, what would\\nwe do?  (signs of the computer age :-)\\n\\nIn closing, please don't let the hateful actions of a single person\\nharm you.  They are doing it because they are still the playground\\nbully and enjoy seeing the hurt they cause.  And you should not\\naccept the opinions of an imbecile that you are worthless - much\\nwiser people hold you in great esteem.\\n-- \\nDarin Johnson\\ndjohnson@ucsd.edu\\n  - Luxury!  In MY day, we had to make do with 5 bytes of swap...\\n\",\n",
              " 'From: s0612596@let.rug.nl (M.M. Zwart)\\nSubject: catholic church poland\\nOrganization: Faculteit der Letteren, Rijksuniversiteit Groningen, NL\\nLines: 10\\n\\nHello,\\n\\nI\\'m writing a paper on the role of the catholic church in Poland after 1989. \\nCan anyone tell me more about this, or fill me in on recent books/articles(\\nin english, german or french). Most important for me is the role of the \\nchurch concerning the abortion-law, religious education at schools,\\nbirth-control and the relation church-state(government). Thanx,\\n\\n                                                 Masja,\\n\"M.M.Zwart\"<s0612596@let.rug.nl>\\n',\n",
              " 'From: stanly@grok11.columbiasc.ncr.com (stanly)\\nSubject: Re: Elder Brother\\nOrganization: NCR Corp., Columbia SC\\nLines: 15\\n\\nIn article <Apr.8.00.57.41.1993.28246@athos.rutgers.edu> REXLEX@fnal.gov writes:\\n>In article <Apr.7.01.56.56.1993.22824@athos.rutgers.edu> shrum@hpfcso.fc.hp.com\\n>Matt. 22:9-14 \\'Go therefore to the main highways, and as many as you find\\n>there, invite to the wedding feast.\\'...\\n\\n>hmmmmmm.  Sounds like your theology and Christ\\'s are at odds. Which one am I \\n>to believe?\\n\\nIn this parable, Jesus tells the parable of the wedding feast. \"The kingdom\\nof heaven is like unto a certain king which made a marriage for his son\".\\nSo the wedding clothes were customary,  and \"given\" to those who \"chose\" to\\nattend.  This man \"refused\" to wear the clothes.  The wedding clothes are\\nequalivant to the \"clothes of righteousness\".  When Jesus died for our sins,\\nthose \"clothes\" were then provided.  Like that man, it is our decision to\\nput the clothes on.\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTz4EaN_1WGc",
        "colab_type": "text"
      },
      "source": [
        "### 9.  Now with dependent and independent data available for both train and test datasets, using TfidfVectorizer fit and transform the training data and test data and get the tfidf features for both"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kukPJ8X_ZiC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HulE7V7WZh8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TfidfVectorizer\n",
        "vect = TfidfVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5G477f81C0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d7434c39-d4c8-4460-edbc-69f3a716b4e4"
      },
      "source": [
        "pd.DataFrame(vect.fit_transform(twenty_train).toarray(), columns=vect.get_feature_names())"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>descr</th>\n",
              "      <th>filenames</th>\n",
              "      <th>target</th>\n",
              "      <th>target_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   data  descr  filenames  target  target_names\n",
              "0   1.0    0.0        0.0     0.0           0.0\n",
              "1   0.0    0.0        1.0     0.0           0.0\n",
              "2   0.0    0.0        0.0     0.0           1.0\n",
              "3   0.0    0.0        0.0     1.0           0.0\n",
              "4   0.0    1.0        0.0     0.0           0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh77q9hhkJVu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df = 4,ngram_range = (1,2),stop_words = \"english\")\n",
        "X_train = vectorizer.fit_transform(twenty_train.data)\n",
        "X_test = vectorizer.transform(twenty_test.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9xC407akJO5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "d3675f0b-bdaf-47f7-92a0-7532d32e9142"
      },
      "source": [
        "pd.DataFrame(X_train.toarray(), columns=vectorizer.get_feature_names()).T"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>2217</th>\n",
              "      <th>2218</th>\n",
              "      <th>2219</th>\n",
              "      <th>2220</th>\n",
              "      <th>2221</th>\n",
              "      <th>2222</th>\n",
              "      <th>2223</th>\n",
              "      <th>2224</th>\n",
              "      <th>2225</th>\n",
              "      <th>2226</th>\n",
              "      <th>2227</th>\n",
              "      <th>2228</th>\n",
              "      <th>2229</th>\n",
              "      <th>2230</th>\n",
              "      <th>2231</th>\n",
              "      <th>2232</th>\n",
              "      <th>2233</th>\n",
              "      <th>2234</th>\n",
              "      <th>2235</th>\n",
              "      <th>2236</th>\n",
              "      <th>2237</th>\n",
              "      <th>2238</th>\n",
              "      <th>2239</th>\n",
              "      <th>2240</th>\n",
              "      <th>2241</th>\n",
              "      <th>2242</th>\n",
              "      <th>2243</th>\n",
              "      <th>2244</th>\n",
              "      <th>2245</th>\n",
              "      <th>2246</th>\n",
              "      <th>2247</th>\n",
              "      <th>2248</th>\n",
              "      <th>2249</th>\n",
              "      <th>2250</th>\n",
              "      <th>2251</th>\n",
              "      <th>2252</th>\n",
              "      <th>2253</th>\n",
              "      <th>2254</th>\n",
              "      <th>2255</th>\n",
              "      <th>2256</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.057652</td>\n",
              "      <td>0.043053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 00</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 08</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 09</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>00 34</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zoerasterism</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zoerasterism shintoism</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zoom</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zyeh</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zyeh caspian</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19877 rows  2257 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                        0     1     2     3     ...  2253  2254  2255  2256\n",
              "00                       0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0\n",
              "00 00                    0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0\n",
              "00 08                    0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0\n",
              "00 09                    0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0\n",
              "00 34                    0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0\n",
              "...                      ...   ...   ...   ...  ...   ...   ...   ...   ...\n",
              "zoerasterism             0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0\n",
              "zoerasterism shintoism   0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0\n",
              "zoom                     0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0\n",
              "zyeh                     0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0\n",
              "zyeh caspian             0.0   0.0   0.0   0.0  ...   0.0   0.0   0.0   0.0\n",
              "\n",
              "[19877 rows x 2257 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp_fDINJ1t4L",
        "colab_type": "text"
      },
      "source": [
        "### 10. Use logisticRegression with tfidf features as input and targets as output and train the model and report the train and test accuracy score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GR-Dn1ymkPD7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "aa40631b-e532-48c8-f579-546dcb998092"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "LRmodel = LogisticRegression()\n",
        "LRmodel.fit(X_train,twenty_train.target)\n",
        "LR_score_train = LRmodel.score(X_train,twenty_train.target)\n",
        "print(\"training score\",LR_score_train)\n",
        "LR_score_test = LRmodel.score(X_test,twenty_test.target)\n",
        "print(\"test score\",LR_score_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training score 0.9955693398316349\n",
            "test score 0.9067909454061251\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}